{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.50\n",
      "두 음성은 다른 목소리입니다.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def extract_features(file_path):\n",
    "    # 음성 파일에서 MFCC 및 추가 특징 추출\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    # 음성 파일을 정규화하여 볼륨 차이 줄이기\n",
    "    y = librosa.util.normalize(y)\n",
    "    \n",
    "    # 특징 추출 (MFCC, Chroma, Spectral Contrast, Spectral Bandwidth)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)  # MFCC 개수를 40으로 증가\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)  # MFCC의 delta 특징 추가\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)  # 추가 특징 추출\n",
    "    \n",
    "    # 추출된 특징의 평균값 및 표준편차 계산하여 반환\n",
    "    features = np.concatenate((\n",
    "        np.mean(mfcc, axis=1),\n",
    "        np.std(mfcc, axis=1),\n",
    "        np.mean(delta_mfcc, axis=1),\n",
    "        np.std(delta_mfcc, axis=1),\n",
    "        np.mean(chroma, axis=1),\n",
    "        np.std(chroma, axis=1),\n",
    "        np.mean(spectral_contrast, axis=1),\n",
    "        np.std(spectral_contrast, axis=1),\n",
    "        np.mean(spectral_bandwidth, axis=1),\n",
    "        np.std(spectral_bandwidth, axis=1)\n",
    "    ))\n",
    "    return features, mfcc\n",
    "\n",
    "def compare_voices(file1, file2):\n",
    "    # 두 파일의 특징 추출\n",
    "    features1, mfcc1 = extract_features(file1)\n",
    "    features2, mfcc2 = extract_features(file2)\n",
    "    \n",
    "    # 동적 시간 왜곡(DTW)을 사용해 MFCC 특징 비교\n",
    "    distance, _ = fastdtw(mfcc1.T, mfcc2.T, dist=euclidean)\n",
    "    \n",
    "    # 코사인 유사도를 사용해 평균 특징 비교\n",
    "    features1 = features1.reshape(1, -1)\n",
    "    features2 = features2.reshape(1, -1)\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    \n",
    "    # 유사도를 0.5 가중치로 합산하여 최종 유사도 계산\n",
    "    final_similarity = 0.5 * (1 / (1 + distance)) + 0.5 * similarity\n",
    "    return final_similarity\n",
    "\n",
    "def is_same_voice(file1, file2, threshold=0.7):\n",
    "    similarity = compare_voices(file1, file2)\n",
    "    print(f\"Similarity: {similarity:.2f}\")\n",
    "    if similarity > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# 사용 예시\n",
    "stored_voice = \"C:\\Projects\\Python_basic\\최종프로젝트\\빨강.mp3\"\n",
    "new_voice = r\"C:\\Projects\\Python_basic\\최종프로젝트\\검정.mp3\"\n",
    "\n",
    "if is_same_voice(stored_voice, new_voice):\n",
    "    print(\"두 음성은 같은 목소리입니다.\")\n",
    "else:\n",
    "    print(\"두 음성은 다른 목소리입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
      "두 음성의 유사도: 0.5281274318695068\n",
      "다른 목소리입니다.\n"
     ]
    }
   ],
   "source": [
    "from resemblyzer import VoiceEncoder, preprocess_wav\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# 모델 로드\n",
    "encoder = VoiceEncoder()\n",
    "\n",
    "# 음성 파일 경로 설정\n",
    "wav_path_1 = Path(r\"C:\\Projects\\Python_basic\\최종프로젝트\\동현.wav\")\n",
    "wav_path_2 = Path(r\"C:\\Projects\\Python_basic\\최종프로젝트\\은설.wav\")\n",
    "\n",
    "# WAV 파일 로드 및 전처리\n",
    "wav_1 = preprocess_wav(wav_path_1)\n",
    "wav_2 = preprocess_wav(wav_path_2)\n",
    "\n",
    "# 음성 임베딩 생성\n",
    "embed_1 = encoder.embed_utterance(wav_1)\n",
    "embed_2 = encoder.embed_utterance(wav_2)\n",
    "\n",
    "# 두 벡터 간 코사인 유사도 계산\n",
    "similarity = np.dot(embed_1, embed_2)\n",
    "print(f\"두 음성의 유사도: {similarity}\")\n",
    "\n",
    "# 유사도가 8.5 이상이면 같은 목소리로 간주\n",
    "if similarity >= 0.80:\n",
    "    print(\"같은 목소리입니다.\")\n",
    "else:\n",
    "    print(\"다른 목소리입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Recording saved as 나비.wav\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import wavio\n",
    "\n",
    "def record_voice(filename=\"나비.wav\", duration=2, samplerate=44100):\n",
    "    print(\"Recording...\")\n",
    "    # 음성 녹음 시작\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=2, dtype='int16')\n",
    "    sd.wait()  # 녹음 완료될 때까지 대기\n",
    "    print(\"Recording finished.\")\n",
    "    \n",
    "    # 녹음한 음성을 파일로 저장\n",
    "    wavio.write(filename, recording, samplerate, sampwidth=2)\n",
    "    print(f\"Recording saved as {filename}\")\n",
    "\n",
    "# 예시: 5초 동안 녹음하고 output.wav로 저장\n",
    "record_voice(duration=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gumi_env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
