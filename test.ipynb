{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 점수: 0.98\n",
      "두 목소리가 유사합니다.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def extract_features(audio_path, sr=22050):\n",
    "    \"\"\"음성 파일로부터 MFCC 특징 추출\"\"\"\n",
    "    audio, _ = librosa.load(audio_path, sr=sr)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "def register_voice(reference_audio_path):\n",
    "    \"\"\"등록된 사용자의 음성 특징 저장\"\"\"\n",
    "    return extract_features(reference_audio_path)\n",
    "\n",
    "def compare_voices(registered_features, new_audio_path):\n",
    "    \"\"\"새로운 음성을 등록된 음성과 비교하여 유사도 계산\"\"\"\n",
    "    new_features = extract_features(new_audio_path)\n",
    "    similarity = cosine_similarity([registered_features], [new_features])\n",
    "    return similarity[0][0]  # 코사인 유사도 반환\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 자신의 목소리 등록 (ex: my_voice.wav)\n",
    "    registered_features = register_voice(\"output.wav\")\n",
    "\n",
    "    # 2. 새로운 목소리와 비교 (ex: other_voice.wav)\n",
    "    similarity_score = compare_voices(registered_features, \"빨강.mp3\")\n",
    "\n",
    "    print(f\"유사도 점수: {similarity_score:.2f}\")\n",
    "\n",
    "    if similarity_score > 0.75:\n",
    "        print(\"두 목소리가 유사합니다.\")\n",
    "    else:\n",
    "        print(\"두 목소리가 다릅니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW 거리: 78795.04337430745\n",
      "유사도 점수: 0.00\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def extract_mfcc(audio_path, sr=22050):\n",
    "    \"\"\"음성 파일에서 MFCC 특징 추출\"\"\"\n",
    "    audio, _ = librosa.load(audio_path, sr=sr)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    return mfccs.T  # 시간 축 기준으로 변환\n",
    "\n",
    "def compute_dtw_distance(mfcc1, mfcc2):\n",
    "    \"\"\"DTW를 사용한 두 음성의 거리 계산\"\"\"\n",
    "    distance, _ = fastdtw(mfcc1, mfcc2, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    return distance\n",
    "\n",
    "# 파일 경로 설정\n",
    "audio1_path = \"검정.mp3\"\n",
    "audio2_path = \"output.wav\"\n",
    "\n",
    "# MFCC 특징 추출\n",
    "mfcc1 = extract_mfcc(audio1_path)\n",
    "mfcc2 = extract_mfcc(audio2_path)\n",
    "\n",
    "# DTW 거리 계산\n",
    "dtw_distance = compute_dtw_distance(mfcc1, mfcc2)\n",
    "\n",
    "print(f\"DTW 거리: {dtw_distance}\")\n",
    "\n",
    "# 유사도 계산 (거리가 작을수록 유사함)\n",
    "similarity_score = np.exp(-dtw_distance / 1000)  # 거리값을 유사도로 변환\n",
    "print(f\"유사도 점수: {similarity_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빨강.mp3 - 샘플링 레이트: 24000, 길이(초): 1.05\n",
      "검정.mp3 - 샘플링 레이트: 16000, 길이(초): 4.992\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# 파일 경로 설정\n",
    "audio1_path = \"빨강.mp3\"\n",
    "audio2_path = \"output.wav\"\n",
    "\n",
    "# 음성 파일 정보 출력\n",
    "audio1, sr1 = librosa.load(audio1_path, sr=None)  # 원본 SR 유지\n",
    "audio2, sr2 = librosa.load(audio2_path, sr=None)  # 원본 SR 유지\n",
    "\n",
    "print(f\"빨강.mp3 - 샘플링 레이트: {sr1}, 길이(초): {len(audio1)/sr1}\")\n",
    "print(f\"검정.mp3 - 샘플링 레이트: {sr2}, 길이(초): {len(audio2)/sr2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1, _ = librosa.load(audio1_path, sr=22050)\n",
    "audio2, _ = librosa.load(audio2_path, sr=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = min(len(audio1), len(audio2))\n",
    "audio1 = audio1[:min_length]\n",
    "audio2 = audio2[:min_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빨강.mp3 - 샘플링 레이트: 24000, 길이(초): 1.05\n",
      "검정.mp3 - 샘플링 레이트: 16000, 길이(초): 4.992\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# 파일 경로 설정\n",
    "audio1_path = \"빨강.mp3\"\n",
    "audio2_path = \"output.wav\"\n",
    "\n",
    "# 음성 파일 정보 출력\n",
    "audio1, sr1 = librosa.load(audio1_path, sr=None)  # 원본 SR 유지\n",
    "audio2, sr2 = librosa.load(audio2_path, sr=None)  # 원본 SR 유지\n",
    "\n",
    "print(f\"빨강.mp3 - 샘플링 레이트: {sr1}, 길이(초): {len(audio1)/sr1}\")\n",
    "print(f\"검정.mp3 - 샘플링 레이트: {sr2}, 길이(초): {len(audio2)/sr2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW 거리: 32648.610815808177\n",
      "유사도 점수: 0.00\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def extract_mfcc(audio, sr=22050):\n",
    "    \"\"\"오디오 데이터로부터 MFCC 추출\"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    return mfccs.T  # 시간 축 기준으로 변환\n",
    "\n",
    "def compute_dtw_distance(mfcc1, mfcc2):\n",
    "    \"\"\"DTW 알고리즘을 이용한 두 음성 간의 거리 계산\"\"\"\n",
    "    distance, _ = fastdtw(mfcc1, mfcc2, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    return distance\n",
    "\n",
    "# 음성 파일 로드 및 샘플링 레이트 맞추기\n",
    "audio1, sr = librosa.load(\"빨강.mp3\", sr=22050)\n",
    "audio2, _ = librosa.load(\"output.wav\", sr=22050)\n",
    "\n",
    "# 음성 길이 맞추기\n",
    "min_len = min(len(audio1), len(audio2))\n",
    "audio1 = audio1[:min_len]\n",
    "audio2 = audio2[:min_len]\n",
    "\n",
    "# MFCC 특징 추출\n",
    "mfcc1 = extract_mfcc(audio1, sr)\n",
    "mfcc2 = extract_mfcc(audio2, sr)\n",
    "\n",
    "# DTW 거리 계산 및 유사도 변환\n",
    "dtw_distance = compute_dtw_distance(mfcc1, mfcc2)\n",
    "similarity_score = np.exp(-dtw_distance / 1000)  # 거리에서 유사도로 변환\n",
    "\n",
    "print(f\"DTW 거리: {dtw_distance}\")\n",
    "print(f\"유사도 점수: {similarity_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW 거리: 251.28373324871063\n",
      "유사도 점수: 0.08\n",
      "두 목소리가 다릅니다.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def extract_features(audio_path, sr=22050):\n",
    "    \"\"\"MFCC와 피치(F0)를 함께 추출\"\"\"\n",
    "    audio, _ = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "    # 1. MFCC 추출\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfccs, axis=1)  # MFCC 평균 계산\n",
    "\n",
    "    # 2. 피치(F0) 추출\n",
    "    pitches, _ = librosa.core.piptrack(y=audio, sr=sr)\n",
    "    pitch_mean = np.mean(pitches[pitches > 0])  # 0이 아닌 피치의 평균값\n",
    "\n",
    "    # 3. 특징 벡터 결합 (MFCC + 피치)\n",
    "    features = np.append(mfcc_mean, pitch_mean)\n",
    "    return features\n",
    "\n",
    "def compare_voices(audio1_path, audio2_path):\n",
    "    \"\"\"두 음성의 MFCC + 피치 기반 유사도 계산\"\"\"\n",
    "    features1 = extract_features(audio1_path)\n",
    "    features2 = extract_features(audio2_path)\n",
    "\n",
    "    # DTW 알고리즘으로 유사도 계산\n",
    "    distance, _ = fastdtw(features1.reshape(-1, 1), features2.reshape(-1, 1), \n",
    "                          dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    \n",
    "    similarity_score = np.exp(-distance / 100)  # 거리값을 유사도로 변환\n",
    "    return distance, similarity_score\n",
    "\n",
    "# 파일 경로 설정\n",
    "audio1_path = \"빨강.mp3\"\n",
    "audio2_path = \"검정.mp3\"\n",
    "\n",
    "# 두 음성 파일 비교\n",
    "distance, similarity = compare_voices(audio1_path, audio2_path)\n",
    "\n",
    "print(f\"DTW 거리: {distance}\")\n",
    "print(f\"유사도 점수: {similarity:.2f}\")\n",
    "\n",
    "if similarity > 0.75:\n",
    "    print(\"두 목소리가 유사합니다.\")\n",
    "else:\n",
    "    print(\"두 목소리가 다릅니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording\n",
      "Predicted Gender: Male\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# 음성을 녹음하는 함수\n",
    "def record_audio(filename, duration=5, rate=44100, channels=1):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=1024)\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for _ in range(0, int(rate / 1024 * duration)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "    \n",
    "    print(\"Finished recording\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "# 성별 분류 모델을 학습하고 저장하는 함수\n",
    "def train_gender_classifier(model_path='gender_classifier.pkl'):\n",
    "    # 데이터 준비 (여기서는 예시로 가상 데이터를 사용)\n",
    "    # 실제로는 남성/여성 음성 데이터를 수집하여 사용해야 합니다.\n",
    "    X = []\n",
    "    y = []\n",
    "    male_data_path = 'data/male'\n",
    "    female_data_path = 'data/female'\n",
    "    \n",
    "    if not os.path.exists(male_data_path) or not os.path.exists(female_data_path):\n",
    "        print(f\"Error: Data directories '{male_data_path}' and '{female_data_path}' not found. Please provide the necessary data.\")\n",
    "        return\n",
    "    \n",
    "    for filename in os.listdir(male_data_path):\n",
    "        filepath = os.path.join(male_data_path, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            audio, sr = librosa.load(filepath, sr=None)\n",
    "            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "            mfcc_mean = np.mean(mfcc, axis=1)\n",
    "            X.append(mfcc_mean)\n",
    "            y.append(1)  # 남성 레이블\n",
    "    for filename in os.listdir(female_data_path):\n",
    "        filepath = os.path.join(female_data_path, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            audio, sr = librosa.load(filepath, sr=None)\n",
    "            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "            mfcc_mean = np.mean(mfcc, axis=1)\n",
    "            X.append(mfcc_mean)\n",
    "            y.append(0)  # 여성 레이블\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # 학습/테스트 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 모델 저장\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # 테스트 및 정확도 출력\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model training complete. Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 녹음한 파일을 이용해 목소리의 성별을 예측하는 함수\n",
    "def predict_gender(filename, model_path='gender_classifier.pkl'):\n",
    "    # 모델이 없으면 학습 후 저장\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Model not found. Training new model...\")\n",
    "        train_gender_classifier(model_path)\n",
    "        if not os.path.exists(model_path):\n",
    "            print(\"Model training failed. Please provide the necessary data.\")\n",
    "            return\n",
    "    \n",
    "    # 녹음된 음성 파일을 로드하고 특징 추출\n",
    "    audio, sr = librosa.load(filename, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    \n",
    "    # 머신러닝 모델 로드\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # 데이터 스케일링 후 성별 예측\n",
    "    scaler = StandardScaler()\n",
    "    mfcc_mean_scaled = scaler.fit_transform([mfcc_mean])\n",
    "    gender_prediction = model.predict(mfcc_mean_scaled)\n",
    "    \n",
    "    if gender_prediction[0] == 1:\n",
    "        print(\"Predicted Gender: Male\")\n",
    "    else:\n",
    "        print(\"Predicted Gender: Female\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 음성을 녹음하여 파일로 저장\n",
    "    record_audio(\"recorded_voice.wav\")\n",
    "    \n",
    "    # 녹음한 음성의 성별을 예측\n",
    "    predict_gender(\"recorded_voice.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording\n",
      "Model training complete. Accuracy: 80.90%\n",
      "Predicted Gender: Male\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# 음성을 녹음하는 함수\n",
    "def record_audio(filename, duration=5, rate=44100, channels=1):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=1024)\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for _ in range(0, int(rate / 1024 * duration)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "    \n",
    "    print(\"Finished recording\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "# 성별 분류 모델을 학습하고 저장하는 함수 (특징 데이터만 사용)\n",
    "def train_gender_classifier_from_csv(csv_path, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # CSV 파일로부터 데이터 로드\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: CSV file '{csv_path}' not found. Please provide the necessary data.\")\n",
    "        return\n",
    "    \n",
    "    data = pd.read_csv(csv_path)\n",
    "    if 'label' not in data.columns:\n",
    "        print(\"Error: CSV file must contain 'label' column.\")\n",
    "        return\n",
    "    \n",
    "    # 'label' 열 값을 숫자로 변환 (male -> 1, female -> 0)\n",
    "    data['label'] = data['label'].map({'male': 1, 'female': 0})\n",
    "    \n",
    "    # 특징 데이터와 라벨 추출 (label 열을 제외한 나머지 열을 특징으로 사용)\n",
    "    X = data.drop(columns=['label']).values\n",
    "    y = data['label'].values\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No valid feature data found in the CSV.\")\n",
    "        return\n",
    "    \n",
    "    # 학습/테스트 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 모델 및 스케일러 저장\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # 테스트 및 정확도 출력\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model training complete. Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 녹음한 파일을 이용해 목소리의 성별을 예측하는 함수\n",
    "def predict_gender(filename, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # 모델과 스케일러가 없으면 학습 후 저장\n",
    "    if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "        print(\"Model or scaler not found. Please train the model first using a CSV file.\")\n",
    "        return\n",
    "    \n",
    "    # 녹음된 음성 파일을 로드하고 특징 추출\n",
    "    audio, sr = librosa.load(filename, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=21)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_mean = mfcc_mean.reshape(1, -1)  # reshape to match the scaler's expected input\n",
    "    \n",
    "    # 머신러닝 모델 및 스케일러 로드\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # 데이터 스케일링 후 성별 예측\n",
    "    mfcc_mean_scaled = scaler.transform(mfcc_mean)\n",
    "    gender_prediction = model.predict(mfcc_mean_scaled)\n",
    "    \n",
    "    if gender_prediction[0] == 1:\n",
    "        print(\"Predicted Gender: Male\")\n",
    "    else:\n",
    "        print(\"Predicted Gender: Female\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 음성을 녹음하여 파일로 저장\n",
    "    record_audio(\"recorded_voice.wav\")\n",
    "    \n",
    "    # CSV 파일에서 모델 학습 (사용자가 CSV 경로를 제공해야 함)\n",
    "    train_gender_classifier_from_csv(r'C:\\Projects\\Python_basic\\최종프로젝트\\further_augmented_voice_data.csv')\n",
    "    \n",
    "    # 녹음한 음성의 성별을 예측\n",
    "    predict_gender(\"recorded_voice.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete. Accuracy: 80.90%\n",
      "Predicted Gender: Female\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# 음성을 파일로부터 로드하여 성별을 예측하는 함수\n",
    "def predict_gender_from_file(filename, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # 모델과 스케일러가 없으면 학습 후 저장\n",
    "    if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "        print(\"Model or scaler not found. Please train the model first using a CSV file.\")\n",
    "        return\n",
    "    \n",
    "    # 음성 파일을 로드하고 특징 추출\n",
    "    audio, sr = librosa.load(filename, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=21)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_mean = mfcc_mean.reshape(1, -1)  # reshape to match the scaler's expected input\n",
    "    \n",
    "    # 머신러닝 모델 및 스케일러 로드\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # 데이터 스케일링 후 성별 예측\n",
    "    mfcc_mean_scaled = scaler.transform(mfcc_mean)\n",
    "    gender_prediction = model.predict(mfcc_mean_scaled)\n",
    "    \n",
    "    if gender_prediction[0] == 1:\n",
    "        print(\"Predicted Gender: Male\")\n",
    "    else:\n",
    "        print(\"Predicted Gender: Female\")\n",
    "\n",
    "# 성별 분류 모델을 학습하고 저장하는 함수 (특징 데이터만 사용)\n",
    "def train_gender_classifier_from_csv(csv_path, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # CSV 파일로부터 데이터 로드\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: CSV file '{csv_path}' not found. Please provide the necessary data.\")\n",
    "        return\n",
    "    \n",
    "    data = pd.read_csv(csv_path)\n",
    "    if 'label' not in data.columns:\n",
    "        print(\"Error: CSV file must contain 'label' column.\")\n",
    "        return\n",
    "    \n",
    "    # 'label' 열 값을 숫자로 변환 (male -> 0, female -> 1)\n",
    "    data['label'] = data['label'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # 특징 데이터와 라벨 추출 (label 열을 제외한 나머지 열을 특징으로 사용)\n",
    "    X = data.drop(columns=['label']).values\n",
    "    y = data['label'].values\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No valid feature data found in the CSV.\")\n",
    "        return\n",
    "    \n",
    "    # 학습/테스트 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 모델 및 스케일러 저장\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # 테스트 및 정확도 출력\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model training complete. Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # CSV 파일에서 모델 학습 (사용자가 CSV 경로를 제공해야 함)\n",
    "    train_gender_classifier_from_csv(r'C:\\Projects\\Python_basic\\최종프로젝트\\further_augmented_voice_data.csv')\n",
    "    \n",
    "    # 음성 파일의 성별을 예측\n",
    "    predict_gender_from_file(r\"C:\\Projects\\Python_basic\\최종프로젝트\\빨강.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording\n",
      "Model training complete. Accuracy: 91.72%\n",
      "Predicted Gender: Male\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "\n",
    "# 음성을 녹음하는 함수\n",
    "def record_audio(filename, duration=5, rate=44100, channels=1):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=1024)\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for _ in range(0, int(rate / 1024 * duration)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "    \n",
    "    print(\"Finished recording\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "# 성별 분류 모델을 학습하고 저장하는 함수 (특징 데이터만 사용)\n",
    "def train_gender_classifier_from_csv(csv_path, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # CSV 파일로부터 데이터 로드\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: CSV file '{csv_path}' not found. Please provide the necessary data.\")\n",
    "        return\n",
    "    \n",
    "    data = pd.read_csv(csv_path)\n",
    "    if 'label' not in data.columns:\n",
    "        print(\"Error: CSV file must contain 'label' column.\")\n",
    "        return\n",
    "    \n",
    "    # 'label' 열 값을 숫자로 변환 (male -> 1, female -> 0)\n",
    "    data['label'] = data['label'].map({'male': 1, 'female': 0})\n",
    "    \n",
    "    # 특징 데이터와 라벨 추출 (label 열을 제외한 나머지 열을 특징으로 사용)\n",
    "    X = data.drop(columns=['label']).values\n",
    "    y = data['label'].values\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No valid feature data found in the CSV.\")\n",
    "        return\n",
    "    \n",
    "    # 학습/테스트 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 모델 및 스케일러 저장\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # 테스트 및 정확도 출력\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model training complete. Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 녹음한 파일을 이용해 목소리의 성별을 예측하는 함수\n",
    "def predict_gender(filename, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # 모델과 스케일러가 없으면 학습 후 저장\n",
    "    if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "        print(\"Model or scaler not found. Please train the model first using a CSV file.\")\n",
    "        return\n",
    "    \n",
    "    # 녹음된 음성 파일을 로드하고 특징 추출\n",
    "    audio, sr = librosa.load(filename, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=21)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_mean = mfcc_mean.reshape(1, -1)  # reshape to match the scaler's expected input\n",
    "    \n",
    "    # 머신러닝 모델 및 스케일러 로드\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # 데이터 스케일링 후 성별 예측\n",
    "    mfcc_mean_scaled = scaler.transform(mfcc_mean)\n",
    "    gender_prediction = model.predict(mfcc_mean_scaled)\n",
    "    \n",
    "    if gender_prediction[0] == 1:\n",
    "        print(\"Predicted Gender: Male\")\n",
    "    else:\n",
    "        print(\"Predicted Gender: Female\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 음성을 녹음하여 파일로 저장\n",
    "    record_audio(\"recorded_voice.wav\")\n",
    "    \n",
    "    # CSV 파일에서 모델 학습 (사용자가 CSV 경로를 제공해야 함)\n",
    "    train_gender_classifier_from_csv(r'C:\\Projects\\Python_basic\\최종프로젝트\\further_augmented_voice_data.csv')\n",
    "    \n",
    "    # 녹음한 음성의 성별을 예측\n",
    "    predict_gender(\"recorded_voice.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete. Accuracy: 91.90%\n",
      "Predicted Gender: Female\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# 음성을 파일로부터 로드하여 성별을 예측하는 함수\n",
    "def predict_gender_from_file(filename, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # 모델과 스케일러가 없으면 학습 후 저장\n",
    "    if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "        print(\"Model or scaler not found. Please train the model first using a CSV file.\")\n",
    "        return\n",
    "    \n",
    "    # 음성 파일을 로드하고 특징 추출\n",
    "    audio, sr = librosa.load(filename, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=21)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_mean = mfcc_mean.reshape(1, -1)  # reshape to match the scaler's expected input\n",
    "    \n",
    "    # 머신러닝 모델 및 스케일러 로드\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # 데이터 스케일링 후 성별 예측\n",
    "    mfcc_mean_scaled = scaler.transform(mfcc_mean)\n",
    "    gender_prediction = model.predict(mfcc_mean_scaled)\n",
    "    \n",
    "    if gender_prediction[0] == 1:\n",
    "        print(\"Predicted Gender: Male\")\n",
    "    else:\n",
    "        print(\"Predicted Gender: Female\")\n",
    "\n",
    "# 성별 분류 모델을 학습하고 저장하는 함수 (특징 데이터만 사용)\n",
    "def train_gender_classifier_from_csv(csv_path, model_path='gender_classifier.pkl', scaler_path='scaler.pkl'):\n",
    "    # CSV 파일로부터 데이터 로드\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: CSV file '{csv_path}' not found. Please provide the necessary data.\")\n",
    "        return\n",
    "    \n",
    "    data = pd.read_csv(csv_path)\n",
    "    if 'label' not in data.columns:\n",
    "        print(\"Error: CSV file must contain 'label' column.\")\n",
    "        return\n",
    "    \n",
    "    # 'label' 열 값을 숫자로 변환 (male -> 0, female -> 1)\n",
    "    data['label'] = data['label'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # 특징 데이터와 라벨 추출 (label 열을 제외한 나머지 열을 특징으로 사용)\n",
    "    X = data.drop(columns=['label']).values\n",
    "    y = data['label'].values\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No valid feature data found in the CSV.\")\n",
    "        return\n",
    "    \n",
    "    # 학습/테스트 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 모델 및 스케일러 저장\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # 테스트 및 정확도 출력\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model training complete. Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # CSV 파일에서 모델 학습 (사용자가 CSV 경로를 제공해야 함)\n",
    "    train_gender_classifier_from_csv(r'C:\\Projects\\Python_basic\\최종프로젝트\\further_augmented_voice_data.csv')\n",
    "    \n",
    "    # 음성 파일의 성별을 예측\n",
    "    predict_gender_from_file(r\"C:\\Projects\\Python_basic\\최종프로젝트\\data\\male\\06_손목이_아파.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 정확도: 79.42%\n",
      "예측된 성별: 남성\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\gumi_env310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "file_path = r'C:\\Projects\\Python_basic\\최종프로젝트\\Male and female Voice data creat by al arman ovi .csv'\n",
    "voice_data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: 데이터 전처리\n",
    "# 특성과 라벨을 분리\n",
    "X = voice_data.drop(columns=['label'])\n",
    "y = voice_data['label']\n",
    "\n",
    "# 라벨을 남성(0), 여성(1)로 변환\n",
    "y = y.map({'male': 0, 'female': 1})\n",
    "\n",
    "# Step 2: 학습 및 테스트 데이터 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: RandomForestClassifier로 모델 학습\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: 테스트 데이터에 대한 예측 및 정확도 확인\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"모델의 정확도: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 5: 음성 파일로부터 학습한 데이터와 동일한 21개의 특징을 추출하는 함수\n",
    "def extract_features_from_audio(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)  # 음성 파일 로드\n",
    "    features = []\n",
    "\n",
    "    # 1. 평균 주파수 관련 값 (meanfreq)\n",
    "    features.append(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "\n",
    "    # 2. 표준 편차 (sd) - 스펙트럼 중심의 표준 편차로 사용\n",
    "    features.append(np.std(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "\n",
    "    # 3. 중앙값 주파수 (median_freq) - 중앙값을 추정\n",
    "    features.append(np.median(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "\n",
    "    # 4. 첫 번째 사분위수 (Q25) - 스펙트럼 롤오프의 25%\n",
    "    features.append(np.percentile(librosa.feature.spectral_rolloff(y=y, sr=sr), 25))\n",
    "\n",
    "    # 5. 세 번째 사분위수 (Q75) - 스펙트럼 롤오프의 75%\n",
    "    features.append(np.percentile(librosa.feature.spectral_rolloff(y=y, sr=sr), 75))\n",
    "\n",
    "    # 6. 스펙트럼 대역폭 (IQR) - 스펙트럼 대역폭을 이용\n",
    "    features.append(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))\n",
    "\n",
    "    # 7. 스펙트럼 플랫니스\n",
    "    features.append(np.mean(librosa.feature.spectral_flatness(y=y)))\n",
    "\n",
    "    # 8-19. MFCC (13개의 MFCC 계수 추출)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_means = np.mean(mfccs.T, axis=0)\n",
    "    features.extend(mfcc_means)\n",
    "\n",
    "    # 추가된 값 - 스펙트럼 롤오프의 평균을 하나만 사용\n",
    "    # 20. 스펙트럼 롤오프 평균\n",
    "    features.append(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "# Step 6: 새로운 음성 파일을 이용해 성별 예측\n",
    "def predict_voice_gender_from_file(file_path):\n",
    "    new_voice_features = extract_features_from_audio(file_path)\n",
    "    if len(new_voice_features) != len(X.columns):\n",
    "        raise ValueError(f\"특징 수가 일치하지 않습니다. 모델은 {len(X.columns)}개의 특징을 기대하지만, {len(new_voice_features)}개의 특징을 입력받았습니다.\")\n",
    "    \n",
    "    prediction = clf.predict([new_voice_features])\n",
    "    if prediction == 0:\n",
    "        return \"남성\"\n",
    "    else:\n",
    "        return \"여성\"\n",
    "\n",
    "# 예시로 새로운 음성 파일을 넣고 성별 예측하기\n",
    "audio_file_path = r'C:\\Projects\\Python_basic\\최종프로젝트\\data\\female\\03_나는_다인이야.wav'  # 새로운 음성 파일 경로 (WAV 또는 MP3)\n",
    "predicted_gender = predict_voice_gender_from_file(audio_file_path)\n",
    "print(f\"예측된 성별: {predicted_gender}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gumi_env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
